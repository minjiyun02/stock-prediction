{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BCXs4VwPtZs",
        "outputId": "3c3af8a1-1562-4644-99f0-7e085108194a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         date   open   high    low  close  volume  change_percent  avg_vol_20d\n",
            "0  1927-12-30  17.66  17.66  17.66  17.66       0             NaN          NaN\n",
            "1  1928-01-03  17.76  17.76  17.76  17.76       0            0.57          NaN\n",
            "2  1928-01-04  17.72  17.72  17.72  17.72       0           -0.23          NaN\n",
            "3  1928-01-05  17.55  17.55  17.55  17.55       0           -0.96          NaN\n",
            "4  1928-01-06  17.66  17.66  17.66  17.66       0            0.63          NaN\n",
            "               open          high           low         close        volume  \\\n",
            "count  24187.000000  24187.000000  24187.000000  24187.000000  2.418700e+04   \n",
            "mean     621.549940    625.206228    617.672947    621.682056  8.840179e+08   \n",
            "std     1001.744483   1007.314809    995.813028   1001.942570  1.585401e+09   \n",
            "min        4.400000      4.400000      4.400000      4.400000  0.000000e+00   \n",
            "25%       24.605000     24.605000     24.605000     24.605000  1.505000e+06   \n",
            "50%      102.000000    102.710000    101.180000    102.000000  1.999000e+07   \n",
            "75%     1007.155000   1015.690000    998.205000   1007.185000  9.324500e+08   \n",
            "max     5257.970200   5264.850100   5245.819800   5254.350100  1.145623e+10   \n",
            "\n",
            "       change_percent   avg_vol_20d  \n",
            "count    24186.000000  2.416800e+04  \n",
            "mean         0.030549  8.833209e+08  \n",
            "std          1.195565  1.556191e+09  \n",
            "min        -20.470000  0.000000e+00  \n",
            "25%         -0.460000  1.609000e+06  \n",
            "50%          0.050000  1.974125e+07  \n",
            "75%          0.550000  9.545362e+08  \n",
            "max         16.610000  7.701906e+09  \n",
            "date               0\n",
            "open               0\n",
            "high               0\n",
            "low                0\n",
            "close              0\n",
            "volume             0\n",
            "change_percent     1\n",
            "avg_vol_20d       19\n",
            "dtype: int64\n",
            "       date   open   high    low  close  change_percent\n",
            "0  19271230  17.66  17.66  17.66  17.66            0.57\n",
            "1  19280103  17.76  17.76  17.76  17.76            0.57\n",
            "2  19280104  17.72  17.72  17.72  17.72           -0.23\n",
            "3  19280105  17.55  17.55  17.55  17.55           -0.96\n",
            "4  19280106  17.66  17.66  17.66  17.66            0.63\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# file import\n",
        "file = 'SP500.csv'\n",
        "data = pd.read_csv(file)\n",
        "\n",
        "print(data.head())\n",
        "print(data.describe())\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# deleting columns not needed for lstm\n",
        "data.drop(\"volume\", inplace = True, axis = 1)\n",
        "data.drop(\"avg_vol_20d\", inplace = True, axis = 1)\n",
        "\n",
        "# set null value for change_percent to 0.57\n",
        "data.fillna(0.57, inplace = True)\n",
        "\n",
        "# reset date format from YYYY-MM-DD to YYYYMMDD for easier input later on\n",
        "data[\"date\"] = pd.to_datetime(data[\"date\"]).dt.strftime(\"%Y%m%d\")\n",
        "\n",
        "# check\n",
        "print(data.head())\n",
        "\n",
        "# save\n",
        "data.to_csv('SP500Processed.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEJBjPa4XHGE",
        "outputId": "a26dcf90-bf18-417f-c375-36009bb0024a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.60285076 -0.60314688 -0.6025482 ]\n",
            " [-0.60275093 -0.60304761 -0.60244778]\n",
            " [-0.60279086 -0.60308732 -0.60248795]\n",
            " ...\n",
            " [ 4.54356817  4.55336142  4.54020021]\n",
            " [ 4.54213025  4.51687753  4.50923984]\n",
            " [ 4.52032793  4.51032572  4.45353576]]\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_16 (LSTM)              (None, 24, 64)            17408     \n",
            "                                                                 \n",
            " lstm_17 (LSTM)              (None, 32)                12416     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29857 (116.63 KB)\n",
            "Trainable params: 29857 (116.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1133/1133 [==============================] - 34s 25ms/step - loss: 0.0019 - val_loss: 5.3766\n",
            "Epoch 2/10\n",
            "1133/1133 [==============================] - 27s 24ms/step - loss: 7.9770e-05 - val_loss: 1.0107\n",
            "Epoch 3/10\n",
            "1133/1133 [==============================] - 26s 23ms/step - loss: 5.2451e-05 - val_loss: 0.1082\n",
            "Epoch 4/10\n",
            "1133/1133 [==============================] - 28s 25ms/step - loss: 5.9192e-05 - val_loss: 0.1802\n",
            "Epoch 5/10\n",
            "1133/1133 [==============================] - 26s 23ms/step - loss: 4.8373e-05 - val_loss: 0.0017\n",
            "Epoch 6/10\n",
            "1133/1133 [==============================] - 30s 26ms/step - loss: 3.8076e-05 - val_loss: 0.0047\n",
            "Epoch 7/10\n",
            "1133/1133 [==============================] - 31s 28ms/step - loss: 3.4860e-05 - val_loss: 0.0082\n",
            "Epoch 8/10\n",
            "1133/1133 [==============================] - 28s 25ms/step - loss: 2.7799e-05 - val_loss: 0.0086\n",
            "Epoch 9/10\n",
            "1133/1133 [==============================] - 27s 24ms/step - loss: 3.6005e-05 - val_loss: 0.0309\n",
            "Epoch 10/10\n",
            "1133/1133 [==============================] - 29s 25ms/step - loss: 2.2807e-05 - val_loss: 0.0148\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv(\"SP500Processed.csv\")\n",
        "\n",
        "# define reformatted dates as dates_train\n",
        "dates_train = data[\"date\"]\n",
        "# change open, high, low, close type to float for normalization\n",
        "ohlc = list(df)[1:4]\n",
        "trainingdf = df[ohlc].astype(float)\n",
        "\n",
        "# initialization for X, y\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "# normalization\n",
        "s = StandardScaler()\n",
        "s = s.fit(trainingdf)\n",
        "scaled = s.transform(trainingdf)\n",
        "print(scaled)\n",
        "\n",
        "# days in the future to predict\n",
        "futuredays = 1\n",
        "\n",
        "# days in the past to use for prediction\n",
        "pastdays = 24\n",
        "\n",
        "# loop to change the X and y train values to take into account future and past days.\n",
        "for i in range(pastdays, len(trainingdf)):\n",
        "  X_train.append(scaled[i - pastdays:i, 0:])\n",
        "  y_train.append(scaled[i + futuredays - 1: i + futuredays, 0])\n",
        "\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "\n",
        "# defining two layer lstm model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units = 64, activation = \"relu\", input_shape = (X_train.shape[1], X_train.shape[2]), return_sequences = True))\n",
        "model.add(LSTM(units = 32, activation = \"relu\", return_sequences = False))\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Dense(y_train.shape[1]))\n",
        "\n",
        "# compiling model\n",
        "model.compile(optimizer = \"adam\", loss = \"mse\")\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs = 10, batch_size = 16 , validation_split = 0.25, verbose = 1)\n",
        "\n",
        "# forecasting (begins on 4/15/2024)\n",
        "futuredays = int(input())\n",
        "forecast_period = pd.date_range(list(dates_train)[-1], periods = futuredays, freq = \"1d\").tolist()\n",
        "prediction = model.predict(X_train[-futuredays: ])\n",
        "\n",
        "# inverse transformation for rescale (duplicate for shape match)\n",
        "shapematch = np.repeat(prediction, trainingdf.shape[1], axis = -1)\n",
        "y_pred = s.inverse_transform(shapematch)[:, 0]\n",
        "\n",
        "forecast_date = []\n",
        "\n",
        "for time_i in forecast_period:\n",
        "  forecast_date.append(time_i.date())\n",
        "\n",
        "# below copied, redo\n",
        "df_forecast = pd.DataFrame({'date':np.array(forecast_date), 'close':y_pred})\n",
        "df_forecast['date']=pd.to_datetime(df_forecast['date'])\n",
        "\n",
        "original = df[['date', 'close']]\n",
        "original['date']=pd.to_datetime(original['date'])\n",
        "original = original.loc[original['date'] >= '2024-5-1']\n",
        "\n",
        "# below gpt\n",
        "sns.lineplot(x='date', y='close', data=df_forecast, label='Prediction', color='orange')\n",
        "sns.lineplot(x='date', y='close', data=original, label='True', color='blue')\n",
        "plt.legend()\n",
        "plt.title('S&P 500 Prediction Graph')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Close Price')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ6SHgX1lSkf"
      },
      "outputs": [],
      "source": [
        "# plot for validation/training loss graph\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsZAE-ASNSHJ"
      },
      "outputs": [],
      "source": [
        "# save\n",
        "model.save('lstm.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}